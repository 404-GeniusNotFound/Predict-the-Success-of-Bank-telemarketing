{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37ba71e",
   "metadata": {},
   "source": [
    "## Step 0: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce413af6",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It begins by importing **LogisticRegression, OneHotEncoder, Pipeline, SMOTE, StratifiedKFold, VotingClassifier, lightgbm, matplotlib, numpy, pandas, roc_auc_score, seaborn, warnings, xgboost** for data handling, modelling, and visualisation. It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning. Finally, it **evaluates model performance** on unseen data. Visualisations are created along the way to illuminate data patterns or results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6653b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf47c43",
   "metadata": {},
   "source": [
    "## Step 1: Load the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e6410",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Next, it **loads external data** so it can be explored and modelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5271f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/predict-the-success-of-bank-telemarketing/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/predict-the-success-of-bank-telemarketing/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5fcbb",
   "metadata": {},
   "source": [
    "## Step 2: Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ce5f8",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The snippet then **cleans or engineers features** to prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_with_missing = ['job', 'education', 'contact', 'poutcome']\n",
    "train_df[categorical_cols_with_missing] = train_df[categorical_cols_with_missing].fillna('unknown')\n",
    "test_df[categorical_cols_with_missing] = test_df[categorical_cols_with_missing].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e7699",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d245a8",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['last contact date'] = pd.to_datetime(train_df['last contact date'])\n",
    "test_df['last contact date'] = pd.to_datetime(test_df['last contact date'])\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['contact_month'] = df['last contact date'].dt.month\n",
    "    df['contact_year'] = df['last contact date'].dt.year\n",
    "    df['contact_dayofweek'] = df['last contact date'].dt.dayofweek\n",
    "    df['contact_day'] = df['last contact date'].dt.day\n",
    "    df['contact_period'] = df['contact_dayofweek'].apply(lambda x: 'weekend' if x >= 5 else 'weekday')\n",
    "\n",
    "train_df.drop(['last contact date'], axis=1, inplace=True)\n",
    "test_df.drop(['last contact date'], axis=1, inplace=True)\n",
    "\n",
    "train_df['target'] = train_df['target'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "train_df['pdays_contacted'] = train_df['pdays'].apply(lambda x: 0 if x == -1 else 1)\n",
    "test_df['pdays_contacted'] = test_df['pdays'].apply(lambda x: 0 if x == -1 else 1)\n",
    "\n",
    "interaction_features = {\n",
    "    'job_marital': ['job', 'marital'],\n",
    "    'job_education': ['job', 'education'],\n",
    "    'housing_loan': ['housing', 'loan'],\n",
    "    'campaign_outcome': ['campaign', 'poutcome']\n",
    "}\n",
    "\n",
    "for new_col, cols in interaction_features.items():\n",
    "    train_df[new_col] = train_df[cols[0]].astype(str) + '_' + train_df[cols[1]].astype(str)\n",
    "    test_df[new_col] = test_df[cols[0]].astype(str) + '_' + test_df[cols[1]].astype(str)\n",
    "\n",
    "skewed_features = ['balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "for col in skewed_features:\n",
    "    min_val = train_df[col].min()\n",
    "    train_df[col + '_log'] = train_df[col].apply(lambda x: np.log(x + abs(min_val) + 1))\n",
    "    test_df[col + '_log'] = test_df[col].apply(lambda x: np.log(x + abs(min_val) + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd46ad1",
   "metadata": {},
   "source": [
    "## Step 4: Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37df20",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2dff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "    'contact', 'poutcome', 'contact_period', 'campaign_outcome',\n",
    "    'job_marital', 'job_education', 'housing_loan',\n",
    "    'contact_month', 'contact_dayofweek'\n",
    "]\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "\n",
    "train_encoded = onehot_encoder.fit_transform(train_df[categorical_features])\n",
    "test_encoded = onehot_encoder.transform(test_df[categorical_features])\n",
    "\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=onehot_encoder.get_feature_names_out(categorical_features))\n",
    "test_encoded_df = pd.DataFrame(test_encoded, columns=onehot_encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "train_encoded_df.index = train_df.index\n",
    "test_encoded_df.index = test_df.index\n",
    "\n",
    "train_df = pd.concat([train_df.drop(columns=categorical_features), train_encoded_df], axis=1)\n",
    "test_df = pd.concat([test_df.drop(columns=categorical_features), test_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac35e5a",
   "metadata": {},
   "source": [
    "## Step 5: Define Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e40d56",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_df.columns if col != 'target']\n",
    "X = train_df[features]\n",
    "y = train_df['target']\n",
    "X_test = test_df[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde39223",
   "metadata": {},
   "source": [
    "## Step 6: Handle Class Imbalance using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40192621",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc171407",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8a58f",
   "metadata": {},
   "source": [
    "## Step 7: Define Models with Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8927246",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15600784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers with the best parameters\n",
    "xgb_best = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    subsample=0.6,\n",
    "    n_estimators=550,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    gamma=0.2,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "lgb_best = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    subsample=1.0,\n",
    "    reg_lambda=0.1,\n",
    "    reg_alpha=0.5,\n",
    "    num_leaves=50,\n",
    "    n_estimators=300,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.6\n",
    ")\n",
    "\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create pipelines for XGBoost and LightGBM with SMOTE\n",
    "xgb_pipeline = ImbPipeline([\n",
    "    ('smote', smote),\n",
    "    ('classifier', xgb_best)\n",
    "])\n",
    "\n",
    "lgb_pipeline = ImbPipeline([\n",
    "    ('smote', smote),\n",
    "    ('classifier', lgb_best)\n",
    "])\n",
    "\n",
    "rf_pipeline = ImbPipeline([\n",
    "    ('smote', smote),\n",
    "    ('classifier', rf_best)\n",
    "])\n",
    "\n",
    "print(\"Models initialized with best parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e035598",
   "metadata": {},
   "source": [
    "## Step 8: Split Data for Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46438df3",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train_full, y_valid_full = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5437f",
   "metadata": {},
   "source": [
    "## Step 9: Train Models on Training Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb8b82",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_pipeline.fit(X_train_full, y_train_full)\n",
    "print(\"XGBoost training completed.\")\n",
    "\n",
    "print(\"\\nTraining LightGBM...\")\n",
    "lgb_pipeline.fit(X_train_full, y_train_full)\n",
    "print(\"LightGBM training completed.\")\n",
    "\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_pipeline.fit(X_train_full, y_train_full)\n",
    "print(\"Random Forest training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc68b57",
   "metadata": {},
   "source": [
    "## Step 10: Predict Probabilities on Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99166b75",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d726d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPredicting probabilities on validation data...\")\n",
    "xgb_valid_proba = xgb_pipeline.predict_proba(X_valid_full)[:, 1]\n",
    "lgb_valid_proba = lgb_pipeline.predict_proba(X_valid_full)[:, 1]\n",
    "rf_valid_proba = rf_pipeline.predict_proba(X_valid_full)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e595f2",
   "metadata": {},
   "source": [
    "## Step 11: Ensemble Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4269caa",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning. Finally, it **evaluates model performance** on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating ROC AUC scores for ensemble weighting...\")\n",
    "xgb_roc_auc = roc_auc_score(y_valid_full, xgb_valid_proba)\n",
    "lgb_roc_auc = roc_auc_score(y_valid_full, lgb_valid_proba)\n",
    "\n",
    "total_auc = xgb_roc_auc + lgb_roc_auc\n",
    "xgb_weight = xgb_roc_auc / total_auc\n",
    "lgb_weight = lgb_roc_auc / total_auc\n",
    "\n",
    "ensemble_weighted_proba = (xgb_valid_proba * xgb_weight) + (lgb_valid_proba * lgb_weight)\n",
    "ensemble_simple_proba = (xgb_valid_proba + lgb_valid_proba) / 2\n",
    "ensemble_soft_proba = ensemble_simple_proba.copy()\n",
    "\n",
    "xgb_valid_pred = xgb_pipeline.predict(X_valid_full)\n",
    "lgb_valid_pred = lgb_pipeline.predict(X_valid_full)\n",
    "\n",
    "ensemble_hard_pred = (xgb_valid_pred + lgb_valid_pred) // 2\n",
    "ensemble_hard_proba = ensemble_hard_pred\n",
    "\n",
    "stack_X = np.vstack((xgb_valid_proba, lgb_valid_proba)).T\n",
    "\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(stack_X, y_valid_full)\n",
    "\n",
    "ensemble_stacking_proba = meta_model.predict_proba(stack_X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15151428",
   "metadata": {},
   "source": [
    "## Step 12: Compile Ensemble Predictions and Calculate F1 Macro Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b60033",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_methods = {\n",
    "    'Weighted Average': ensemble_weighted_proba,\n",
    "    'Simple Average': ensemble_simple_proba,\n",
    "    'Soft Voting': ensemble_soft_proba,\n",
    "    'Hard Voting': ensemble_hard_proba,\n",
    "    'Stacking': ensemble_stacking_proba\n",
    "}\n",
    "\n",
    "manual_threshold = 0.325\n",
    "\n",
    "f1_scores_dict = {}\n",
    "\n",
    "print(\"\\nCalculating F1 Macro Scores for ensemble methods:\")\n",
    "for method, proba in ensemble_methods.items():\n",
    "    if method == 'Hard Voting':\n",
    "        pred = proba\n",
    "    else:\n",
    "        pred = (proba >= manual_threshold).astype(int)\n",
    "    f1 = f1_score(y_valid_full, pred, average='macro')\n",
    "    f1_scores_dict[method] = f1\n",
    "    print(f\"F1 Macro Score (Validation) for {method}: {f1:.6f} with Threshold: {manual_threshold}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081824cc",
   "metadata": {},
   "source": [
    "## Step 13: Visualization of F1 Macro Scores Across Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60043584",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Visualisations are created along the way to illuminate data patterns or results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(f1_scores_dict.keys()), y=list(f1_scores_dict.values()), palette='viridis')\n",
    "plt.ylabel('F1 Macro Score')\n",
    "plt.title('F1 Macro Score Comparison Across Ensemble Methods')\n",
    "plt.ylim(0, 1)\n",
    "for index, value in enumerate(f1_scores_dict.values()):\n",
    "    plt.text(index, value + 0.01, f\"{value:.4f}\", ha='center')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416c5bf",
   "metadata": {},
   "source": [
    "## Step 14: Feature Importance Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e7f84",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning. Visualisations are created along the way to illuminate data patterns or results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, model_name, top_n=20):\n",
    "    if model_name == 'XGBoost':\n",
    "        booster = model.named_steps['classifier'].get_booster()\n",
    "        importance = booster.get_score(importance_type='weight')\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': list(importance.keys()),\n",
    "            'importance': list(importance.values())\n",
    "        }).sort_values(by='importance', ascending=False).head(top_n)\n",
    "    elif model_name == 'LightGBM':\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': model.named_steps['classifier'].feature_name_,\n",
    "            'importance': model.named_steps['classifier'].feature_importances_\n",
    "        }).sort_values(by='importance', ascending=False).head(top_n)\n",
    "    elif model_name == 'Random Forest':\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': model.named_steps['classifier'].feature_names_in_,\n",
    "            'importance': model.named_steps['classifier'].feature_importances_\n",
    "        }).sort_values(by='importance', ascending=False).head(top_n)\n",
    "    else:\n",
    "        raise ValueError(\"Model name not recognized. Use 'XGBoost', 'LightGBM', or 'Random Forest'.\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df, palette='viridis')\n",
    "    plt.title(f'Top {top_n} Feature Importances - {model_name}')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nPlotting Feature Importances...\")\n",
    "plot_feature_importance(xgb_pipeline, 'XGBoost')\n",
    "plot_feature_importance(lgb_pipeline, 'LightGBM')\n",
    "plot_feature_importance(rf_pipeline, 'Random Forest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d408d",
   "metadata": {},
   "source": [
    "## Step 15: Additional Performance Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf63a0",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Finally, it **evaluates model performance** on unseen data. Visualisations are created along the way to illuminate data patterns or results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2efd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve_custom(y_true, y_scores, model_name):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc_score(y_true, y_scores):.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nPlotting ROC Curves for Ensemble Methods...\")\n",
    "for method, proba in ensemble_methods.items():\n",
    "    if method != 'Hard Voting':\n",
    "        plot_roc_curve_custom(y_valid_full, proba, method)\n",
    "\n",
    "def plot_confusion_matrix_custom(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nPlotting Confusion Matrices for Ensemble Methods...\")\n",
    "for method, proba in ensemble_methods.items():\n",
    "    if method == 'Hard Voting':\n",
    "        pred = proba\n",
    "    else:\n",
    "        pred = (proba >= manual_threshold).astype(int)\n",
    "    plot_confusion_matrix_custom(y_valid_full, pred, method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae5c4f",
   "metadata": {},
   "source": [
    "## Step 16: Retrain Models on Full Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959c1c1",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "It proceeds to **train a machine‑learning model** with appropriate hyper‑parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0183d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRetraining models on the full dataset...\")\n",
    "xgb_pipeline.fit(X, y)\n",
    "lgb_pipeline.fit(X, y)\n",
    "rf_pipeline.fit(X, y)\n",
    "print(\"Retraining completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4485cf",
   "metadata": {},
   "source": [
    "## Step 17: Ensemble Methods on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec1f82",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Finally, it **evaluates model performance** on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPredicting probabilities on test data...\")\n",
    "xgb_test_proba = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
    "lgb_test_proba = lgb_pipeline.predict_proba(X_test)[:, 1]\n",
    "rf_test_proba = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ensemble_weighted_test_proba = (xgb_test_proba * xgb_weight) + (lgb_test_proba * lgb_weight)\n",
    "ensemble_simple_test_proba = (xgb_test_proba + lgb_test_proba) / 2\n",
    "ensemble_soft_test_proba = ensemble_simple_test_proba.copy()\n",
    "ensemble_hard_pred = (xgb_pipeline.predict(X_test) + lgb_pipeline.predict(X_test)) // 2\n",
    "ensemble_hard_test_proba = ensemble_hard_pred\n",
    "stack_X_test = np.vstack((xgb_test_proba, lgb_test_proba)).T\n",
    "ensemble_stacking_test_proba = meta_model.predict_proba(stack_X_test)[:, 1]\n",
    "\n",
    "test_ensemble_methods = {\n",
    "    'Weighted Average': ensemble_weighted_test_proba,\n",
    "    'Simple Average': ensemble_simple_test_proba,\n",
    "    'Soft Voting': ensemble_soft_test_proba,\n",
    "    'Hard Voting': ensemble_hard_test_proba,\n",
    "    'Stacking': ensemble_stacking_test_proba\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf2198",
   "metadata": {},
   "source": [
    "## Step 18: Prepare Submission for the Best Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b39978",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This code cell performs a necessary step in the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method = max(f1_scores_dict, key=f1_scores_dict.get)\n",
    "best_f1_score = f1_scores_dict[best_method]\n",
    "print(f\"\\nBest Ensemble Method: {best_method} with F1 Macro Score: {best_f1_score:.6f}\")\n",
    "\n",
    "best_test_proba = test_ensemble_methods[best_method]\n",
    "\n",
    "if best_method == 'Hard Voting':\n",
    "    best_test_pred = best_test_proba\n",
    "else:\n",
    "    best_test_pred = (best_test_proba >= manual_threshold).astype(int)\n",
    "\n",
    "pred_mapped = np.where(best_test_pred == 1, 'yes', 'no')\n",
    "\n",
    "if 'client_id' in test_df.columns:\n",
    "    identifier = test_df['client_id']\n",
    "else:\n",
    "    identifier = test_df.index\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': identifier,\n",
    "    'target': pred_mapped\n",
    "})\n",
    "\n",
    "submission_filename = 'submission.csv'\n",
    "\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "print(f\"\\nSubmission File Created for the Best Ensemble Method ({best_method}): {submission_filename}\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9578279,
     "sourceId": 85062,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 359.514204,
   "end_time": "2024-11-29T18:40:42.109087",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-29T18:34:42.594883",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
